import requests
from bs4 import BeautifulSoup
import time

# ==== KONFIGURACJA ====
DISCORD_WEBHOOK = "https://discord.com/api/webhooks/1430120682758471710/oSF0KcorzVj74oL91zLz-wRdtdnh3QCed-B9Vz5pQw_mmi5CdCiT4bDv4tjg5eS1tK6k"
SEARCH_TERMS = ["iphone", "samsung galaxy", "xiaomi"]
CHECK_INTERVAL = 60  # czas w sekundach

# ===== Funkcja wysy≈ÇajƒÖca wiadomo≈õci na Discord =====
def send_discord(title, price, url, location, platform):
    data = {
        "username": "AukcjeBot",
        "embeds": [{
            "title": f"{title} ({platform})",
            "url": url,
            "description": f"üí∏ Cena: {price}\nüìç Lokalizacja: {location}",
            "color": 0x00ff00
        }]
    }
    try:
        requests.post(DISCORD_WEBHOOK, json=data)
    except Exception as e:
        print("B≈ÇƒÖd przy wysy≈Çaniu na Discord:", e)

# ===== Funkcja scraper Allegro =====
def scrape_allegro(term):
    url = f"https://allegro.pl/listing?string={term}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers)
        soup = BeautifulSoup(r.text, "html.parser")
        offers = soup.select("div.selling")[:5]  # pierwsze 5 ofert
        results = []
        for o in offers:
            title_tag = o.select_one("h2")
            price_tag = o.select_one("span._1svub._lf05o")
            url_tag = o.select_one("a")
            location_tag = o.select_one("span._1lbi1")
            if title_tag and price_tag and url_tag:
                results.append({
                    "title": title_tag.text.strip(),
                    "price": price_tag.text.strip(),
                    "url": url_tag['href'],
                    "location": location_tag.text.strip() if location_tag else "Nieznana"
                })
        return results
    except Exception as e:
        print("Allegro b≈ÇƒÖd:", e)
        return []

# ===== Funkcja scraper OLX =====
def scrape_olx(term):
    url = f"https://www.olx.pl/oferty/q-{term}/"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers)
        soup = BeautifulSoup(r.text, "html.parser")
        offers = soup.select("li[data-cy='l-card']")[:5]
        results = []
        for o in offers:
            title_tag = o.select_one("h6")
            price_tag = o.select_one("p")
            url_tag = o.select_one("a")
            location_tag = o.select_one("span[data-testid='location-date']")
            if title_tag and price_tag and url_tag:
                results.append({
                    "title": title_tag.text.strip(),
                    "price": price_tag.text.strip(),
                    "url": url_tag['href'],
                    "location": location_tag.text.strip() if location_tag else "Nieznana"
                })
        return results
    except Exception as e:
        print("OLX b≈ÇƒÖd:", e)
        return []

# ===== Funkcja scraper Vinted =====
def scrape_vinted(term):
    url = f"https://www.vinted.pl/catalog?search_text={term}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers)
        soup = BeautifulSoup(r.text, "html.parser")
        offers = soup.select("div.catalog-item")[:5]
        results = []
        for o in offers:
            title_tag = o.select_one("a.catalog-item__title")
            price_tag = o.select_one("div.catalog-item__price")
            url_tag = o.select_one("a.catalog-item__link")
            location_tag = o.select_one("div.catalog-item__location")
            if title_tag and price_tag and url_tag:
                results.append({
                    "title": title_tag.text.strip(),
                    "price": price_tag.text.strip(),
                    "url": "https://www.vinted.pl" + url_tag['href'],
                    "location": location_tag.text.strip() if location_tag else "Nieznana"
                })
        return results
    except Exception as e:
        print("Vinted b≈ÇƒÖd:", e)
        return []

# ===== G≈Ç√≥wna pƒôtla =====
already_seen = set()

while True:
    for term in SEARCH_TERMS:
        for offer in scrape_allegro(term):
            key = (offer['title'], offer['price'], offer['url'])
            if key not in already_seen:
                send_discord(offer['title'], offer['price'], offer['url'], offer['location'], "Allegro")
                already_seen.add(key)
        for offer in scrape_olx(term):
            key = (offer['title'], offer['price'], offer['url'])
            if key not in already_seen:
                send_discord(offer['title'], offer['price'], offer['url'], offer['location'], "OLX")
                already_seen.add(key)
        for offer in scrape_vinted(term):
            key = (offer['title'], offer['price'], offer['url'])
            if key not in already_seen:
                send_discord(offer['title'], offer['price'], offer['url'], offer['location'], "Vinted")
                already_seen.add(key)
    time.sleep(CHECK_INTERVAL)
