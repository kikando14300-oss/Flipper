# kod - bot + keep-alive dla Replit
import os
import threading
import time
import requests
from bs4 import BeautifulSoup
from flask import Flask

# ===== KONFIGURACJA =====
DISCORD_WEBHOOK = os.getenv("DISCORD_WEBHOOK") or "TU_WKLEJ_SW√ìJ_LINK_WEBHOOK"
SEARCH_TERMS = ["iphone", "samsung galaxy", "xiaomi"]  # edytuj wedle potrzeby
CHECK_INTERVAL = 60  # sekundy - zmie≈Ñ je≈õli chcesz rzadziej/co szybciej

# ===== FUNKCJA DO WYSY≈ÅANIA NA DISCORD =====
def send_discord(title, price, url, location, platform):
    if not DISCORD_WEBHOOK:
        print("Brak DISCORD_WEBHOOK")
        return
    payload = {
        "username": "AukcjeBot",
        "embeds": [{
            "title": f"{title} ({platform})",
            "url": url,
            "description": f"üí∏ Cena: {price}\nüìç Lokalizacja: {location}",
        }]
    }
    try:
        r = requests.post(DISCORD_WEBHOOK, json=payload, timeout=10)
        if r.status_code >= 400:
            print("Discord error", r.status_code, r.text)
    except Exception as e:
        print("B≈ÇƒÖd wys≈Çania do Discord:", e)

# ===== SCRAPER ALLEGRO =====
def scrape_allegro(term):
    url = f"https://allegro.pl/listing?string={term}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(r.text, "html.parser")
        # selektory mogƒÖ siƒô r√≥≈ºniƒá w zale≈ºno≈õci od strony - bierzemy bezpieczne elementy
        items = []
        # szukamy element√≥w artyku≈Çu ‚Äî przeglƒÖdamy linki
        for a in soup.select("a[href]"):
            href = a.get("href")
            if href and "/offer/" in href:
                title = a.get_text(strip=True)
                # spr√≥buj znale≈∫ƒá cenƒô w rodzicu
                parent = a.find_parent()
                price = "Brak"
                if parent:
                    p = parent.select_one("span[data-role='price'], span._1svub")
                    if p:
                        price = p.get_text(strip=True)
                items.append({"title": title or "Brak tytu≈Çu", "price": price, "url": href if href.startswith("http") else ("https://allegro.pl" + href), "location": "‚Äî"})
        # unikalne i pierwsze 8
        seen = set(); out = []
        for it in items:
            key = (it["title"], it["price"], it["url"])
            if key in seen: continue
            seen.add(key); out.append(it)
            if len(out) >= 8: break
        return out
    except Exception as e:
        print("Allegro b≈ÇƒÖd:", e)
        return []

# ===== SCRAPER OLX =====
def scrape_olx(term):
    url = f"https://www.olx.pl/oferty/q-{term}/"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(r.text, "html.parser")
        out = []
        for li in soup.select("a[href]"):
            href = li.get("href")
            if href and "/oferta/" in href:
                title = li.get_text(strip=True)
                # znajd≈∫ cenƒô w sƒÖsiednich elementach
                parent = li.find_parent()
                price = "Brak"
                if parent:
                    p = parent.select_one("p")
                    if p:
                        price = p.get_text(strip=True)
                out.append({"title": title or "Brak", "price": price, "url": href, "location": "‚Äî"})
            if len(out) >= 8: break
        return out
    except Exception as e:
        print("OLX b≈ÇƒÖd:", e)
        return []

# ===== SCRAPER VINTED =====
def scrape_vinted(term):
    url = f"https://www.vinted.pl/catalog?search_text={term}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(r.text, "html.parser")
        out = []
        for a in soup.select("a[href]"):
            href = a.get("href")
            if href and "/item/" in href:
                title = a.get_text(strip=True)
                # cena
                price = "Brak"
                parent = a.find_parent()
                if parent:
                    p = parent.select_one(".catalog-item__price, .price")
                    if p:
                        price = p.get_text(strip=True)
                url_full = href if href.startswith("http") else ("https://www.vinted.pl" + href)
                out.append({"title": title or "Brak", "price": price, "url": url_full, "location": "‚Äî"})
            if len(out) >= 8: break
        return out
    except Exception as e:
        print("Vinted b≈ÇƒÖd:", e)
        return []

# ===== G≈Å√ìWNA PƒòTLA BOTA (dzia≈Ça w tle) =====
def bot_loop():
    already_seen = set()
    while True:
        try:
            for term in SEARCH_TERMS:
                # Allegro
                offers = scrape_allegro(term)
                for o in offers:
                    key = (o['title'], o['price'], o['url'])
                    if key not in already_seen:
                        print("Nowa (Allegro):", o['title'], o['price'])
                        send_discord(o['title'], o['price'], o['url'], o.get('location','‚Äî'), "Allegro")
                        already_seen.add(key)
                # OLX
                offers = scrape_olx(term)
                for o in offers:
                    key = (o['title'], o['price'], o['url'])
                    if key not in already_seen:
                        print("Nowa (OLX):", o['title'], o['price'])
                        send_discord(o['title'], o['price'], o['url'], o.get('location','‚Äî'), "OLX")
                        already_seen.add(key)
                # Vinted
                offers = scrape_vinted(term)
                for o in offers:
                    key = (o['title'], o['price'], o['url'])
                    if key not in already_seen:
                        print("Nowa (Vinted):", o['title'], o['price'])
                        send_discord(o['title'], o['price'], o['url'], o.get('location','‚Äî'), "Vinted")
                        already_seen.add(key)
        except Exception as e:
            print("B≈ÇƒÖd w pƒôtli bota:", e)
        time.sleep(CHECK_INTERVAL)

# ===== FLASK KEEP-ALIVE (dla Replit + UptimeRobot) =====
app = Flask("keepalive")

@app.route("/")
def home():
    return "OK", 200

def run_flask():
    port = int(os.getenv("PORT", 8080))
    app.run(host="0.0.0.0", port=port)

if __name__ == "__main__":
    # start bot w tle
    t = threading.Thread(target=bot_loop, daemon=True)
    t.start()
    # start serwera strony (keep-alive)
    run_flask()
